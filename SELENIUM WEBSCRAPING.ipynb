{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9db313ab",
   "metadata": {},
   "source": [
    "# Instructions \n",
    "WEB SCRAPING – ASSIGNMENT 2 \n",
    "1. All the questions must be done in a single Jupyter notebook. 2. There should be proper comments in code. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da297b31",
   "metadata": {},
   "source": [
    "## Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 jobs data. This task will be done in following steps: \n",
    "1. First get the webpage https://www.naukri.com/ 2. Enter “Data Analyst” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the location” field. 3. Then click the search button. 4. Then scrape the data for the first 10 jobs results you get. 5. Finally create a dataframe of the scraped data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "afbce83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52c93eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to webdriver\n",
    "driver=webdriver.Chrome(r'E:\\chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95779397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get webpage\n",
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba117ee8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"ecf9cd6defc4adf646ea14d6a9efa783\", element=\"32b4cf19-db34-4dd2-9079-4b069497d9a6\")>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find web element for search bar using class name\n",
    "search_job = driver.find_element(By.CLASS_NAME,'suggestor-input')\n",
    "search_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3930efe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#write on search bar\n",
    "search_job.send_keys(\"Data Analyst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9441eabb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"ecf9cd6defc4adf646ea14d6a9efa783\", element=\"a54747d0-1234-496f-99f9-45830481ea46\")>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finding web element for search location bar using relative Xpath \n",
    "search_loc = driver.find_element(By.XPATH,\"/html/body/div[1]/div[2]/div[3]/div/div/div[5]/div/div/div/input\")\n",
    "search_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c4fb1f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding web element for job locatin bar\n",
    "search_loc.send_keys(\"Bangalore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "24d13894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"ecf9cd6defc4adf646ea14d6a9efa783\", element=\"6e6cd5d0-d95b-4a24-8b91-6d2ec7c6c5c6\")>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#clicking using web absolute xpath function \n",
    "search_btn=driver.find_element(By.XPATH,\"/html/body/div[1]/div[2]/div[3]/div/div/div[6]\")\n",
    "search_btn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bb417786",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c295b0a6",
   "metadata": {},
   "source": [
    "## Extracting Job Titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b5fd2bf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#extract all the web element having job titles\n",
    "title_tags = driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')\n",
    "len(title_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d0859f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty list to scraping data into them\n",
    "\n",
    "job_title=[]\n",
    "company_name=[]\n",
    "experience_required=[]\n",
    "job_location=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a515c51c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below are the top 10 job data's job title: \n",
      " ['Sr.Business Data Analyst', 'Sr Data Analyst', 'Senior Data Analysis Analyst', 'Job opportunity For Data Analyst at Trellance - India', 'Data Analyst', 'Senior Data Analyst', 'Associate Data Analyst', 'Associate Data Analyst', 'Data Analyst/Senior Data Analyst', 'Financial Data Analyst']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in title_tags:\n",
    "    title = i.text\n",
    "    job_title.append(title)\n",
    "job_title = job_title[0:10]\n",
    "\n",
    "print(\"Below are the top 10 job data's job title: \\n\", job_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9676a20b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"ecf9cd6defc4adf646ea14d6a9efa783\", element=\"53f440e0-5636-40e8-b417-a8922ecc00b7\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"ecf9cd6defc4adf646ea14d6a9efa783\", element=\"f0cb3406-7f91-4245-9e6e-a83e39b81c53\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"ecf9cd6defc4adf646ea14d6a9efa783\", element=\"16e3d73f-baff-4606-9fbf-a536e4da3ae4\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"ecf9cd6defc4adf646ea14d6a9efa783\", element=\"d537e346-a545-45e2-a0c9-623fcb9af1e1\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"ecf9cd6defc4adf646ea14d6a9efa783\", element=\"cc31cdc8-651e-4834-819b-3cf6e2351279\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"ecf9cd6defc4adf646ea14d6a9efa783\", element=\"02914364-0c35-4eee-8898-d092899e323c\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"ecf9cd6defc4adf646ea14d6a9efa783\", element=\"f7e474e6-0028-496e-a931-0bfeb261311a\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"ecf9cd6defc4adf646ea14d6a9efa783\", element=\"c342ee30-5109-4e6c-a691-5b188db093eb\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"ecf9cd6defc4adf646ea14d6a9efa783\", element=\"486f7ec4-7d59-4c84-a4f1-51f19374e348\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"ecf9cd6defc4adf646ea14d6a9efa783\", element=\"f449a24e-1c6a-4114-88e3-9fab041e07bd\")>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extracting all the tags having company name\n",
    "\n",
    "company_tag = driver.find_elements(By.XPATH,\"//a[@class='subTitle ellipsis fleft']\")\n",
    "company_tag[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b22a8f72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below are the top 10 job data's : \n",
      " ['Cerner', 'Flipkart', 'Wells Fargo', 'Happay-Expense Management Solution for Businesses', 'Kititan Co., Ltd', 'Artech infosystem', \"Moody's\", \"Moody's\", \"Moody's\", 'Schneider Electric']\n"
     ]
    }
   ],
   "source": [
    "# extract the job title text iteratively from these tags one by one\n",
    "\n",
    "for i in company_tag:\n",
    "    company = i.text\n",
    "    company_name.append(company)\n",
    "company_name = company_name[10:20]\n",
    "print(\"Below are the top 10 job data's : \\n\", company_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "13be9f06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"ecf9cd6defc4adf646ea14d6a9efa783\", element=\"3be6d80e-42ee-4b39-ad18-a05b45b37ccb\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"ecf9cd6defc4adf646ea14d6a9efa783\", element=\"235420b4-7a8e-412f-99cf-afa52127acb1\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"ecf9cd6defc4adf646ea14d6a9efa783\", element=\"8c772531-49ea-4282-af14-e64b2f97c15e\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"ecf9cd6defc4adf646ea14d6a9efa783\", element=\"1ed4bfb9-09d8-4919-9348-2346bdd61170\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"ecf9cd6defc4adf646ea14d6a9efa783\", element=\"fd65c4b9-ca52-4f11-bd8b-241972c9f14b\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"ecf9cd6defc4adf646ea14d6a9efa783\", element=\"932dbcfa-287f-4a21-a41e-5ec5716ef90b\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"ecf9cd6defc4adf646ea14d6a9efa783\", element=\"7698e81c-a5c4-4dda-8168-d63234745b79\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"ecf9cd6defc4adf646ea14d6a9efa783\", element=\"a1dbfa55-70ff-436d-b28a-cf7be0a52f7f\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"ecf9cd6defc4adf646ea14d6a9efa783\", element=\"e06b5c65-0b3d-4dd3-8d8c-3352317e058a\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"ecf9cd6defc4adf646ea14d6a9efa783\", element=\"bd69b793-1eee-45af-8811-2afccd2d093a\")>]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extracting all the tags having job-experience\n",
    "\n",
    "exp_tag = driver.find_elements(By.XPATH,\"//li[@class='fleft grey-text br2 placeHolderLi experience']\")\n",
    "exp_tag[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "19494f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below are the top 10 job data's job title: \n",
      " ['6-11', '5-8', '7-12', '0-2', '2-3', '3-6', '2-7', '1-4', '3-6', '3-8']\n"
     ]
    }
   ],
   "source": [
    "# extract the job experience text iteratively from these tags one by one\n",
    "\n",
    "for i in exp_tag: \n",
    "    experience_required.append(i.text.split(\" \")[0])\n",
    "experience_required= experience_required[0:10]\n",
    "print(\"Below are the top 10 job data's job title: \\n\", experience_required)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ea4aa7b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"ecf9cd6defc4adf646ea14d6a9efa783\", element=\"da70102f-6e6c-4003-922c-0d9ff6ab2276\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"ecf9cd6defc4adf646ea14d6a9efa783\", element=\"df2c513f-47eb-4821-a6d4-780d9004615d\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"ecf9cd6defc4adf646ea14d6a9efa783\", element=\"9a541b02-2df3-436d-bb2e-3baf3d03bf30\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"ecf9cd6defc4adf646ea14d6a9efa783\", element=\"4aa95ba6-fddc-45bc-8b01-b3307b121178\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"ecf9cd6defc4adf646ea14d6a9efa783\", element=\"4e694e60-7427-44e0-bdc6-e2eefec74c2b\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"ecf9cd6defc4adf646ea14d6a9efa783\", element=\"45927948-9c28-48b8-9627-0c4b071b4c0a\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"ecf9cd6defc4adf646ea14d6a9efa783\", element=\"581b3c05-3fa9-4957-b7d3-57457a7f69b2\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"ecf9cd6defc4adf646ea14d6a9efa783\", element=\"12a68a4e-b568-4528-b398-a2155941445a\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"ecf9cd6defc4adf646ea14d6a9efa783\", element=\"d9ce6143-21b8-4747-9d07-cbec8707c4fa\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"ecf9cd6defc4adf646ea14d6a9efa783\", element=\"16fd3c70-9625-4b35-8ad5-93afcda86a82\")>]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extracting all the tags having job-location \n",
    "\n",
    "location_tag = driver.find_elements(By.XPATH,\"//li[@class='fleft grey-text br2 placeHolderLi location']\")\n",
    "location_tag[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "359f45c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below are the top 10 job data's company location \n",
      " ['Bangalore/Bengaluru, karnataka\\n(WFH during Covid)', 'Bangalore/Bengaluru', 'Bangalore/Bengaluru, Pune, Chennai', 'Bangalore/Bengaluru, Ahmedabad', 'Bangalore/Bengaluru', 'Bangalore/Bengaluru(Old Madras Road)', 'Bangalore/Bengaluru', 'Bangalore/Bengaluru', 'Bangalore/Bengaluru', 'Bangalore/Bengaluru']\n"
     ]
    }
   ],
   "source": [
    "for i in location_tag:\n",
    "    location = i.text\n",
    "    job_location.append(location)\n",
    "job_location = job_location[0:10]\n",
    "print(\"Below are the top 10 job data's company location \\n\", job_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "45d5c47a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sr.Business Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru, karnataka\\n(WFH during Co...</td>\n",
       "      <td>Cerner</td>\n",
       "      <td>6-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sr Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Flipkart</td>\n",
       "      <td>5-8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior Data Analysis Analyst</td>\n",
       "      <td>Bangalore/Bengaluru, Pune, Chennai</td>\n",
       "      <td>Wells Fargo</td>\n",
       "      <td>7-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Job opportunity For Data Analyst at Trellance ...</td>\n",
       "      <td>Bangalore/Bengaluru, Ahmedabad</td>\n",
       "      <td>Happay-Expense Management Solution for Businesses</td>\n",
       "      <td>0-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Kititan Co., Ltd</td>\n",
       "      <td>2-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru(Old Madras Road)</td>\n",
       "      <td>Artech infosystem</td>\n",
       "      <td>3-6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Associate Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Moody's</td>\n",
       "      <td>2-7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Associate Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Moody's</td>\n",
       "      <td>1-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Analyst/Senior Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Moody's</td>\n",
       "      <td>3-6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Financial Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Schneider Electric</td>\n",
       "      <td>3-8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0                           Sr.Business Data Analyst   \n",
       "1                                    Sr Data Analyst   \n",
       "2                       Senior Data Analysis Analyst   \n",
       "3  Job opportunity For Data Analyst at Trellance ...   \n",
       "4                                       Data Analyst   \n",
       "5                                Senior Data Analyst   \n",
       "6                             Associate Data Analyst   \n",
       "7                             Associate Data Analyst   \n",
       "8                   Data Analyst/Senior Data Analyst   \n",
       "9                             Financial Data Analyst   \n",
       "\n",
       "                                            Location  \\\n",
       "0  Bangalore/Bengaluru, karnataka\\n(WFH during Co...   \n",
       "1                                Bangalore/Bengaluru   \n",
       "2                 Bangalore/Bengaluru, Pune, Chennai   \n",
       "3                     Bangalore/Bengaluru, Ahmedabad   \n",
       "4                                Bangalore/Bengaluru   \n",
       "5               Bangalore/Bengaluru(Old Madras Road)   \n",
       "6                                Bangalore/Bengaluru   \n",
       "7                                Bangalore/Bengaluru   \n",
       "8                                Bangalore/Bengaluru   \n",
       "9                                Bangalore/Bengaluru   \n",
       "\n",
       "                                        Company_Name Experience  \n",
       "0                                             Cerner       6-11  \n",
       "1                                           Flipkart        5-8  \n",
       "2                                        Wells Fargo       7-12  \n",
       "3  Happay-Expense Management Solution for Businesses        0-2  \n",
       "4                                   Kititan Co., Ltd        2-3  \n",
       "5                                  Artech infosystem        3-6  \n",
       "6                                            Moody's        2-7  \n",
       "7                                            Moody's        1-4  \n",
       "8                                            Moody's        3-6  \n",
       "9                                 Schneider Electric        3-8  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# making DataFrame of the top 10 job details from the \"wwww.naukri.com\"\n",
    "\n",
    "naukri_analytics = pd.DataFrame({'Title':job_title, \n",
    "                       'Location': job_location,\n",
    "                       'Company_Name':company_name, \n",
    "                       'Experience':experience_required,                        \n",
    "                       })\n",
    "naukri_analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfc7847",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "52272f09",
   "metadata": {},
   "source": [
    "# Q2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name. You have to scrape first 10 jobs data. This task will be done in following steps: ##1. First get the webpage https://www.naukri.com/ 2. Enter “Data Scientist” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the location” field. 3. Then click the search button. 4. Then scrape the data for the first 10 jobs results you get. 5. Finally create a dataframe of the scraped data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d8dc2714",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(\"chromedriver.exe\")\n",
    "\n",
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "52ee69a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_field_designation=driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "search_field_designation.send_keys(\"Data Scientist\")\n",
    "search_location=driver.find_element(By.XPATH,'/html/body/div/div[2]/div[3]/div/div/div[5]/div/div/div/input')\n",
    "search_location.send_keys(\"Banglore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9ebc63dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"be96467c2446114807b665feed2a6c66\", element=\"5a2b8bb9-c221-4157-8e7a-d51a48a96f66\")>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#clicking using web absolute xpath function \n",
    "search_btn=driver.find_element(By.XPATH,\"/html/body/div[1]/div[2]/div[3]/div/div/div[6]\")\n",
    "search_btn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "60a32dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "78cbcbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty list to scraping data into them\n",
    "\n",
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "63a03c46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"be96467c2446114807b665feed2a6c66\", element=\"89cf8437-4ba9-493c-9f54-a1bf2a46646d\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"be96467c2446114807b665feed2a6c66\", element=\"d6208c92-fb18-4a8e-b973-55fea8df4026\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"be96467c2446114807b665feed2a6c66\", element=\"69b360a6-e0be-4369-af02-bf7745ab7b5e\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"be96467c2446114807b665feed2a6c66\", element=\"92f1ddb3-e83d-4cc0-b077-cad0ef08236e\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"be96467c2446114807b665feed2a6c66\", element=\"8b6866cf-b4b1-4137-bfd5-020eaa1a2e73\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"be96467c2446114807b665feed2a6c66\", element=\"584dcbf3-680b-40f6-8913-3eb156b41823\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"be96467c2446114807b665feed2a6c66\", element=\"8e2de4d4-3e09-4a5d-8b08-80f7d02de6a8\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"be96467c2446114807b665feed2a6c66\", element=\"e31db98d-cf2d-43fd-ad72-500b35089650\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"be96467c2446114807b665feed2a6c66\", element=\"1ab73417-980a-4eae-8bb2-d3712a66cb53\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"be96467c2446114807b665feed2a6c66\", element=\"082158b1-303e-47c1-a5da-dd714725e086\")>]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extracting all the tags having job-titles\n",
    "\n",
    "title_tag = driver.find_elements(By.XPATH,\"//a[@class='title fw500 ellipsis']\")\n",
    "title_tag[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "86ec4f9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below are the top 10 job data's job title: \n",
      " ['Data Scientist/ Senior Data Scientist', 'Urgent Job Opening For AI Practitioner - Data Science at Wipro Holmes', 'Dataiku Consultant', 'Data Scientist', 'Data & Analytics Tech - Informatica Cloud- Senior Associate', 'Data Scientist: Advanced Analytics', 'Research Scientist', 'Data Science - Senior Data Scientist - Analytics', 'Principal - Data Scientist', 'Research and Development -AI/ML -(PhD )']\n"
     ]
    }
   ],
   "source": [
    "# extract the job title text iteratively from these tags one by one\n",
    "\n",
    "for i in title_tag:\n",
    "    title = i.text\n",
    "    job_title.append(title)\n",
    "job_title = job_title[0:10]\n",
    "\n",
    "print(\"Below are the top 10 job data's job title: \\n\", job_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9f7a77d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"be96467c2446114807b665feed2a6c66\", element=\"06e8fdda-78f6-4912-b561-0d9d07eff72a\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"be96467c2446114807b665feed2a6c66\", element=\"31cc3a57-211c-4963-aefe-4daacf938d06\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"be96467c2446114807b665feed2a6c66\", element=\"46582b5f-0860-43e5-8541-e51869359df1\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"be96467c2446114807b665feed2a6c66\", element=\"b2550095-970a-4933-920d-e33169745f60\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"be96467c2446114807b665feed2a6c66\", element=\"55763f88-5ae7-4c3c-939e-562ed974df1d\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"be96467c2446114807b665feed2a6c66\", element=\"fc77979a-8f17-45d4-a703-171aa94f59b8\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"be96467c2446114807b665feed2a6c66\", element=\"e5012e14-1a06-48f8-9a9c-8df95859fe54\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"be96467c2446114807b665feed2a6c66\", element=\"d6ae3a4d-96ba-4492-8302-b1e15440eab3\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"be96467c2446114807b665feed2a6c66\", element=\"49f43c1d-a747-44fd-bcce-1dc9ae254656\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"be96467c2446114807b665feed2a6c66\", element=\"53d4b7b6-8136-4b38-9086-33c212412771\")>]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extracting all the tags having job-location \n",
    "\n",
    "location_tag = driver.find_elements(By.XPATH,\"//li[@class='fleft grey-text br2 placeHolderLi location']\")\n",
    "location_tag[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "eebefe1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below are the top 10 job data's company location \n",
      " ['Pune, Gurgaon/Gurugram, Chennai, Bangalore/Bengaluru, Mumbai (All Areas)', 'Kochi/Cochin, New Delhi, Bangalore/Bengaluru, Coimbatore, Chennai, Pune, Mumbai, Hyderabad', 'Pune, Chennai, Bangalore/Bengaluru', 'Bangalore/Bengaluru', 'Bangalore/Bengaluru', 'Bangalore/Bengaluru', 'Bangalore/Bengaluru', 'Noida, Bangalore/Bengaluru', 'Bangalore/Bengaluru', 'Noida, Hyderabad/Secunderabad, Pune, Gurgaon/Gurugram, Chennai, Bangalore/Bengaluru, Delhi / NCR']\n"
     ]
    }
   ],
   "source": [
    "# extract the job location text iteratively from these tags one by one\n",
    "\n",
    "for i in location_tag:\n",
    "    location = i.text\n",
    "    job_location.append(location)\n",
    "job_location = job_location[0:10]\n",
    "print(\"Below are the top 10 job data's company location \\n\", job_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f85ec014",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"be96467c2446114807b665feed2a6c66\", element=\"ddd7b258-9852-42e0-a4b7-adcdd110cfeb\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"be96467c2446114807b665feed2a6c66\", element=\"da74c782-6211-44a0-b99f-11c94726d537\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"be96467c2446114807b665feed2a6c66\", element=\"49bc4b22-d713-4a7f-822c-23e77668e345\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"be96467c2446114807b665feed2a6c66\", element=\"e48decb7-70f9-43e0-bb89-31d1aa954314\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"be96467c2446114807b665feed2a6c66\", element=\"5a145301-5c30-46ba-9564-5936fe338177\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"be96467c2446114807b665feed2a6c66\", element=\"1267e7ea-f947-4b93-a3ad-edace10c190f\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"be96467c2446114807b665feed2a6c66\", element=\"79b63e58-d70f-419d-a548-4c945932782c\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"be96467c2446114807b665feed2a6c66\", element=\"b3a85624-6d02-4adb-ab52-c89bba42ea17\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"be96467c2446114807b665feed2a6c66\", element=\"8d003da9-136d-46ec-8fc6-35d9a7cf98dd\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"be96467c2446114807b665feed2a6c66\", element=\"b6cebd84-a2a4-42da-81b1-8989e36ed224\")>]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extracting all the tags having company name\n",
    "\n",
    "company_tag = driver.find_elements(By.XPATH,\"//a[@class='subTitle ellipsis fleft']\")\n",
    "company_tag[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8c5ba709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below are the top 10 job data's : \n",
      " ['Fractal Analytics', 'Wipro', 'Wipro', 'Applied Materials', 'PwC', 'IBM', 'IBM', 'Paytm', 'Schneider Electric', 'EXL']\n"
     ]
    }
   ],
   "source": [
    "# extract the company name text iteratively from these tags one by one\n",
    "\n",
    "for i in company_tag:\n",
    "    company = i.text\n",
    "    company_name.append(company)\n",
    "company_name = company_name[0:10]\n",
    "print(\"Below are the top 10 job data's : \\n\", company_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "826e0a36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company_Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist/ Senior Data Scientist</td>\n",
       "      <td>Pune, Gurgaon/Gurugram, Chennai, Bangalore/Ben...</td>\n",
       "      <td>Fractal Analytics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Urgent Job Opening For AI Practitioner - Data ...</td>\n",
       "      <td>Kochi/Cochin, New Delhi, Bangalore/Bengaluru, ...</td>\n",
       "      <td>Wipro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dataiku Consultant</td>\n",
       "      <td>Pune, Chennai, Bangalore/Bengaluru</td>\n",
       "      <td>Wipro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Applied Materials</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data &amp; Analytics Tech - Informatica Cloud- Sen...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>PwC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist: Advanced Analytics</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>IBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Research Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>IBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Science - Senior Data Scientist - Analytics</td>\n",
       "      <td>Noida, Bangalore/Bengaluru</td>\n",
       "      <td>Paytm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Principal - Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Schneider Electric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Research and Development -AI/ML -(PhD )</td>\n",
       "      <td>Noida, Hyderabad/Secunderabad, Pune, Gurgaon/G...</td>\n",
       "      <td>EXL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0              Data Scientist/ Senior Data Scientist   \n",
       "1  Urgent Job Opening For AI Practitioner - Data ...   \n",
       "2                                 Dataiku Consultant   \n",
       "3                                     Data Scientist   \n",
       "4  Data & Analytics Tech - Informatica Cloud- Sen...   \n",
       "5                 Data Scientist: Advanced Analytics   \n",
       "6                                 Research Scientist   \n",
       "7   Data Science - Senior Data Scientist - Analytics   \n",
       "8                         Principal - Data Scientist   \n",
       "9            Research and Development -AI/ML -(PhD )   \n",
       "\n",
       "                                            Location        Company_Name  \n",
       "0  Pune, Gurgaon/Gurugram, Chennai, Bangalore/Ben...   Fractal Analytics  \n",
       "1  Kochi/Cochin, New Delhi, Bangalore/Bengaluru, ...               Wipro  \n",
       "2                 Pune, Chennai, Bangalore/Bengaluru               Wipro  \n",
       "3                                Bangalore/Bengaluru   Applied Materials  \n",
       "4                                Bangalore/Bengaluru                 PwC  \n",
       "5                                Bangalore/Bengaluru                 IBM  \n",
       "6                                Bangalore/Bengaluru                 IBM  \n",
       "7                         Noida, Bangalore/Bengaluru               Paytm  \n",
       "8                                Bangalore/Bengaluru  Schneider Electric  \n",
       "9  Noida, Hyderabad/Secunderabad, Pune, Gurgaon/G...                 EXL  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# making DataFrame of the top 10 job details from the \"wwww.naukri.com\"\n",
    "\n",
    "naukri_scientist = pd.DataFrame({'Title':job_title, \n",
    "                       'Location': job_location,\n",
    "                       'Company_Name':company_name,                                   \n",
    "                       })\n",
    "naukri_scientist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a804b2",
   "metadata": {},
   "source": [
    "# Q3: In this question you have to scrape data using the filters available on the webpage as shown below:\n",
    "You have to use the location and salary filter.\n",
    "You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "You have to scrape the job-title, job-location, company name, experience required.\n",
    "The location filter to be used is “Delhi/NCR” The salary filter to be used is “3-6” lakhs\n",
    "The task will be done as shown in the below steps:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf2bcfc",
   "metadata": {},
   "source": [
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill, Designations, and Companies” field.\n",
    "3. Then click the search button.\n",
    "4. Then apply the location filter and salary filter by checking the respective boxes\n",
    "5. Then scrape the data for the first 10 jobs results you get.\n",
    "6. Finally create a dataframe of the scraped data.\n",
    "Note: All of the above steps have to be done in code. No step is to be done manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5d880f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(\"chromedriver.exe\")\n",
    "\n",
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6364d1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter “Data Scientist” in “Skill, Designations, Companies” field.\n",
    "search_job = driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "search_job.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "045e3de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_button=driver.find_element(By.XPATH,'/html/body/div/div[2]/div[3]/div/div/div[6]')\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7e501d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the location filter \"Delhi-NCR\" and salary \"3-6 lakh\" filter by checking the respective boxes\n",
    "\n",
    "loc_clk=driver.find_elements(By.XPATH,\"//span[@class='ellipsis fleft']\")\n",
    "for i in loc_clk:\n",
    "    if i.text == 'Delhi / NCR':   \n",
    "        i.click() # Checking the checkbox to apply filter on the location\n",
    "        break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8c44e94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying salary filter\n",
    "sal_clk=driver.find_elements(By.XPATH,\"//span[@class='ellipsis fleft']\")\n",
    "for i in sal_clk:\n",
    "    if i.text == '3-6 Lakhs':   \n",
    "        i.click() # Checking the checkbox to apply filter on the salary\n",
    "        break  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b909f85",
   "metadata": {},
   "source": [
    "Scraping the data for the first 10 jobs results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "afee3c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specifying the url of the webpage to be scraped\n",
    "url = \"https://www.naukri.com/data-scientist-jobs?k=data%20scientist&cityTypeGid=9508&ctcFilter=3to6\"\n",
    "\n",
    "# open the webpage through our web driver\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7e6187ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty list to scraping data into them\n",
    "\n",
    "job_title=[]\n",
    "company_name=[]\n",
    "job_location=[]\n",
    "experience_required=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c2831047",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"25501162880b9a7b261815090f0f08cf\", element=\"e087f0bf-ef5c-4f0c-b407-9756e3bedf4c\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"25501162880b9a7b261815090f0f08cf\", element=\"0654534a-ad1d-4b89-93df-43866678d213\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"25501162880b9a7b261815090f0f08cf\", element=\"fd5af763-f33e-4e4a-a02d-39cf4001c048\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"25501162880b9a7b261815090f0f08cf\", element=\"a006f90d-275c-428a-a249-ebbb3c28f8f7\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"25501162880b9a7b261815090f0f08cf\", element=\"956e34c0-f3c1-4bf9-800e-2c28ae0c0527\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"25501162880b9a7b261815090f0f08cf\", element=\"a7556174-c515-4a16-9f2b-786f43b7d81b\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"25501162880b9a7b261815090f0f08cf\", element=\"ca678e24-be30-4b1a-9b9f-628cac56cda8\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"25501162880b9a7b261815090f0f08cf\", element=\"3be9252f-43a1-45a5-aeb7-1185bdd5c477\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"25501162880b9a7b261815090f0f08cf\", element=\"a55d2729-65d2-491f-9490-c2c5b3daf378\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"25501162880b9a7b261815090f0f08cf\", element=\"1a955e7c-89d2-4c2e-ac84-8410c88f1861\")>]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extracting all the tags having job-titles\n",
    "\n",
    "title_tag = driver.find_elements(By.XPATH,\"//a[@class='title fw500 ellipsis']\")\n",
    "title_tag[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "794a46fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LIST of top 10 job data's job title: \n",
      " ['DigitalBCG GAMMA Data Scientist', 'Data Scientist - Noida/Bangalore', 'Senior Associate - Data Science', 'Data Scientist For Healthcare Product team', 'Data Scientist - Machine learning AI', 'Data Scientist - MIND Infotech', 'Data Scientist - Engine Algorithm', 'Knowledge/Data Scientist', 'Data Scientist', 'Data Scientist']\n"
     ]
    }
   ],
   "source": [
    "# extract the job title text iteratively from these tags one by one\n",
    "\n",
    "for i in title_tag:\n",
    "    title = i.text\n",
    "    job_title.append(title)\n",
    "job_title = job_title[0:10]\n",
    "\n",
    "print(\"LIST of top 10 job data's job title: \\n\", job_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "971b6316",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"25501162880b9a7b261815090f0f08cf\", element=\"87aa43cc-b4a6-4802-a7fd-28d1ae3e88ba\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"25501162880b9a7b261815090f0f08cf\", element=\"c0c8b53a-cd12-4dce-a733-0928f2839fb9\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"25501162880b9a7b261815090f0f08cf\", element=\"9b6272d5-3ada-4d85-9538-4f4af27f9a53\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"25501162880b9a7b261815090f0f08cf\", element=\"d1ca047e-bf15-4389-8c4c-524d3340fe4d\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"25501162880b9a7b261815090f0f08cf\", element=\"3ca86045-c3f3-4879-abc1-e9224dd56037\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"25501162880b9a7b261815090f0f08cf\", element=\"7e5fe5f5-5ce8-47c1-bd27-792f11d542f2\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"25501162880b9a7b261815090f0f08cf\", element=\"bc60b624-02b9-48e1-b086-a3a2cbf1accd\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"25501162880b9a7b261815090f0f08cf\", element=\"387d85ea-6447-466c-8cb1-2e6b47d64ade\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"25501162880b9a7b261815090f0f08cf\", element=\"be968846-be84-4751-9bc0-4cd337155836\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"25501162880b9a7b261815090f0f08cf\", element=\"737736d0-49f5-49a4-bef1-56aefac9a9c5\")>]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extracting all the tags having job-location \n",
    "\n",
    "location_tag = driver.find_elements(By.XPATH,\"//li[@class='fleft grey-text br2 placeHolderLi location']\")\n",
    "location_tag[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ac544ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LIST OF top 10 job data's company location \n",
      " ['New Delhi, Bangalore/Bengaluru', 'Noida, Bangalore/Bengaluru', 'Mumbai, Hyderabad/Secunderabad, Gurgaon/Gurugram, Bangalore/Bengaluru', 'Delhi / NCR, Chennai, Bangalore/Bengaluru', 'Delhi / NCR, Bangalore/Bengaluru, Mumbai (All Areas)\\n(WFH during Covid)', 'Noida', 'Delhi / NCR, Kolkata, Mumbai, Hyderabad/Secunderabad, Lucknow, Chennai, Ahmedabad, Bangalore/Bengaluru', 'Delhi / NCR', 'Delhi / NCR, Pune, Bangalore/Bengaluru', 'Delhi / NCR, Pune, Bangalore/Bengaluru']\n"
     ]
    }
   ],
   "source": [
    "# extract the job location text iteratively from these tags one by one\n",
    "\n",
    "for i in location_tag:\n",
    "    location = i.text\n",
    "    job_location.append(location)\n",
    "job_location = job_location[0:10]\n",
    "print(\"LIST OF top 10 job data's company location \\n\", job_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "13713262",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"25501162880b9a7b261815090f0f08cf\", element=\"63a4bac7-d166-464e-917b-693141ac7e49\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"25501162880b9a7b261815090f0f08cf\", element=\"1ad04120-f68d-476b-b632-eb5611c7638d\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"25501162880b9a7b261815090f0f08cf\", element=\"2f02baf7-c100-469d-8da2-888fb488a82f\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"25501162880b9a7b261815090f0f08cf\", element=\"abe5113f-79da-4d09-9d68-ea2b9176788c\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"25501162880b9a7b261815090f0f08cf\", element=\"e3ad1ac9-3ef8-4e60-b995-43e754fcf488\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"25501162880b9a7b261815090f0f08cf\", element=\"c9d5ef1f-9dc2-4393-a24f-82d66efa3ec0\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"25501162880b9a7b261815090f0f08cf\", element=\"42e115dc-ee9a-467c-9a0c-0dd35bf3a49a\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"25501162880b9a7b261815090f0f08cf\", element=\"69e253d0-1b2d-429d-8734-3e028837d671\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"25501162880b9a7b261815090f0f08cf\", element=\"ec0b9d5e-6b04-4aba-bd97-3920e49aee92\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"25501162880b9a7b261815090f0f08cf\", element=\"d7f4a75f-c5fc-4835-a071-1aa6bf02f292\")>]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extracting all the tags having company name\n",
    "\n",
    "company_tag = driver.find_elements(By.XPATH,\"//a[@class='subTitle ellipsis fleft']\")\n",
    "company_tag[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5377851f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LIST top 10 job data's : \n",
      " ['Boston Consulting Group', 'EXL', 'Black Turtle', '8KMiles Software Services', 'Teq Analytics', 'MOTHERSONSUMI INFOTECH & DESIGNS LIMITED', 'Primo Hiring', 'BOLD Technology Systems', 'Mount Talent Consulting Private Limited', 'Mount Talent Consulting Private Limited']\n"
     ]
    }
   ],
   "source": [
    "# extract the company name text iteratively from these tags one by one\n",
    "\n",
    "for i in company_tag:\n",
    "    company = i.text\n",
    "    company_name.append(company)\n",
    "company_name = company_name[0:10]\n",
    "print(\"LIST top 10 job data's : \\n\", company_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9cd31c19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"25501162880b9a7b261815090f0f08cf\", element=\"7fcf4f4c-2761-417d-b66a-b848d697c47e\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"25501162880b9a7b261815090f0f08cf\", element=\"bc0a7bf3-a652-4c97-8110-23470995b092\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"25501162880b9a7b261815090f0f08cf\", element=\"15e35b06-2eb1-4ebf-b690-3889522281cf\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"25501162880b9a7b261815090f0f08cf\", element=\"df98a827-25ad-4260-bea7-dbd2384f956e\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"25501162880b9a7b261815090f0f08cf\", element=\"d2543c18-b0e1-4598-a465-389547e30284\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"25501162880b9a7b261815090f0f08cf\", element=\"72a43253-df86-4df7-9f11-20702cefa054\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"25501162880b9a7b261815090f0f08cf\", element=\"781f1bd1-7ff5-4254-a8da-d353d622c660\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"25501162880b9a7b261815090f0f08cf\", element=\"c12e535c-f190-4245-af8a-2cc3ade4d603\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"25501162880b9a7b261815090f0f08cf\", element=\"b45f366d-bbb0-4413-8820-2309437a550d\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"25501162880b9a7b261815090f0f08cf\", element=\"1593ecc9-25f2-4b53-b71c-2c00a97b63de\")>]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extracting all the tags having job-experience\n",
    "\n",
    "exp_tag = driver.find_elements(By.XPATH,\"//li[@class='fleft grey-text br2 placeHolderLi experience']\")\n",
    "exp_tag[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "73793158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " LIST top 10 job data's job title: \n",
      " ['2-5 ', '5-10 ', '4-7 ', '2-7 ', '3-8 ', '4-8 ', '1-3 ', '3-6 ', '2-4 ', '2-4 ']\n"
     ]
    }
   ],
   "source": [
    "# extract the job experience text iteratively from these tags one by one\n",
    "\n",
    "for i in exp_tag:\n",
    "    experience_required.append(i.text.replace(\"Yrs\",\"\"))\n",
    "experience_required= experience_required[0:10]\n",
    "print(\" LIST top 10 job data's job title: \\n\", experience_required)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ae3148f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DigitalBCG GAMMA Data Scientist</td>\n",
       "      <td>New Delhi, Bangalore/Bengaluru</td>\n",
       "      <td>Boston Consulting Group</td>\n",
       "      <td>2-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist - Noida/Bangalore</td>\n",
       "      <td>Noida, Bangalore/Bengaluru</td>\n",
       "      <td>EXL</td>\n",
       "      <td>5-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior Associate - Data Science</td>\n",
       "      <td>Mumbai, Hyderabad/Secunderabad, Gurgaon/Gurugr...</td>\n",
       "      <td>Black Turtle</td>\n",
       "      <td>4-7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist For Healthcare Product team</td>\n",
       "      <td>Delhi / NCR, Chennai, Bangalore/Bengaluru</td>\n",
       "      <td>8KMiles Software Services</td>\n",
       "      <td>2-7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist - Machine learning AI</td>\n",
       "      <td>Delhi / NCR, Bangalore/Bengaluru, Mumbai (All ...</td>\n",
       "      <td>Teq Analytics</td>\n",
       "      <td>3-8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist - MIND Infotech</td>\n",
       "      <td>Noida</td>\n",
       "      <td>MOTHERSONSUMI INFOTECH &amp; DESIGNS LIMITED</td>\n",
       "      <td>4-8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist - Engine Algorithm</td>\n",
       "      <td>Delhi / NCR, Kolkata, Mumbai, Hyderabad/Secund...</td>\n",
       "      <td>Primo Hiring</td>\n",
       "      <td>1-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Knowledge/Data Scientist</td>\n",
       "      <td>Delhi / NCR</td>\n",
       "      <td>BOLD Technology Systems</td>\n",
       "      <td>3-6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Delhi / NCR, Pune, Bangalore/Bengaluru</td>\n",
       "      <td>Mount Talent Consulting Private Limited</td>\n",
       "      <td>2-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Delhi / NCR, Pune, Bangalore/Bengaluru</td>\n",
       "      <td>Mount Talent Consulting Private Limited</td>\n",
       "      <td>2-4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Title  \\\n",
       "0             DigitalBCG GAMMA Data Scientist   \n",
       "1            Data Scientist - Noida/Bangalore   \n",
       "2             Senior Associate - Data Science   \n",
       "3  Data Scientist For Healthcare Product team   \n",
       "4        Data Scientist - Machine learning AI   \n",
       "5              Data Scientist - MIND Infotech   \n",
       "6           Data Scientist - Engine Algorithm   \n",
       "7                    Knowledge/Data Scientist   \n",
       "8                              Data Scientist   \n",
       "9                              Data Scientist   \n",
       "\n",
       "                                            Location  \\\n",
       "0                     New Delhi, Bangalore/Bengaluru   \n",
       "1                         Noida, Bangalore/Bengaluru   \n",
       "2  Mumbai, Hyderabad/Secunderabad, Gurgaon/Gurugr...   \n",
       "3          Delhi / NCR, Chennai, Bangalore/Bengaluru   \n",
       "4  Delhi / NCR, Bangalore/Bengaluru, Mumbai (All ...   \n",
       "5                                              Noida   \n",
       "6  Delhi / NCR, Kolkata, Mumbai, Hyderabad/Secund...   \n",
       "7                                        Delhi / NCR   \n",
       "8             Delhi / NCR, Pune, Bangalore/Bengaluru   \n",
       "9             Delhi / NCR, Pune, Bangalore/Bengaluru   \n",
       "\n",
       "                               Company_Name Experience  \n",
       "0                   Boston Consulting Group       2-5   \n",
       "1                                       EXL      5-10   \n",
       "2                              Black Turtle       4-7   \n",
       "3                 8KMiles Software Services       2-7   \n",
       "4                             Teq Analytics       3-8   \n",
       "5  MOTHERSONSUMI INFOTECH & DESIGNS LIMITED       4-8   \n",
       "6                              Primo Hiring       1-3   \n",
       "7                   BOLD Technology Systems       3-6   \n",
       "8   Mount Talent Consulting Private Limited       2-4   \n",
       "9   Mount Talent Consulting Private Limited       2-4   "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# making DataFrame of the top 10 job details from the \"wwww.naukri.com\"\n",
    "\n",
    "naukri_filter = pd.DataFrame({'Title':job_title, \n",
    "                       'Location': job_location,\n",
    "                       'Company_Name':company_name, \n",
    "                       'Experience':experience_required,                        \n",
    "                       })\n",
    "naukri_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2199ee42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5cfa24ba",
   "metadata": {},
   "source": [
    "# Q4: Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes: 1. Brand 2. Product Description 3. Price"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7103a61a",
   "metadata": {},
   "source": [
    "To scrape the data you have to go through following steps: 1. Go to Flipkart webpage by url : https://www.flipkart.com/ 2. Enter “sunglasses” in the search field where “search for products, brands and more” is written and click the search icon 3. After that you will reach to the page having a lot of sunglasses. From this page you can scrap the required data as usual.\n",
    " \n",
    "4. After scraping data from the first page, go to the “Next” Button at the bottom other page , then click on it. 5. Now scrape data from this page as usual 6. Repeat this until you get data for 100 sunglasses. Note"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "5359530b",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(\"chromedriver.exe\")\n",
    "\n",
    "driver.get(\"https://www.flipkart.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "26eaff51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter “sunglasses” in “search for products, brands and more” field.\n",
    "search_product = driver.find_element(By.XPATH,\"//div[@class='_3OO5Xc']/input\")\n",
    "search_product.send_keys(\"sunglasses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "fcd4bd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# click the search button\n",
    "search_btn = driver.find_element(By.XPATH,\"//button[@class='L0Z3Pu']\")\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "5812400f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specifying the url of the webpage to be scraped\n",
    "url = \"https://www.flipkart.com/search?q=sunglasses&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off\"\n",
    "\n",
    "# open the webpage through our web driver\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24efdbf",
   "metadata": {},
   "source": [
    "Scraping the data for the first 100 sunglasses "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "fd87cfe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterating first 3 website pages to scrape the data\n",
    "\n",
    "page_url=[]\n",
    "\n",
    "url=driver.find_elements(By.XPATH,\"//nav[@class='yFHi8N']//a\")\n",
    "for i in url:\n",
    "    page_url.append(i.get_attribute('href'))\n",
    "page_url=page_url[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "633f9a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty list to scraping data into them\n",
    "\n",
    "brand=[]\n",
    "Description=[]\n",
    "Price=[]\n",
    "Discount=[] \n",
    "\n",
    "# extracting all the tags\n",
    "\n",
    "for i in page_url:\n",
    "    driver.get(i)\n",
    "    titles_brand=driver.find_elements(By.XPATH,\"//div[@class='_2WkVRV']\")\n",
    "    for i in titles_brand:\n",
    "        brand.append(i.text)\n",
    "        \n",
    "    titles_Description=driver.find_elements(By.XPATH,\"//a[@class='IRpwTa']\")\n",
    "    for i in titles_Description:\n",
    "        Description.append(i.text)\n",
    "        \n",
    "    titles_Price=driver.find_elements(By.XPATH,\"//div[@class='_30jeq3']\")\n",
    "    for i in titles_Price:\n",
    "        Price.append(i.text.replace(\"₹\",\"\"))\n",
    "        \n",
    "    titles_Discount=driver.find_elements(By.XPATH,\"//div[@class='_3Ay6Sb']/span\")\n",
    "    for i in titles_Discount:\n",
    "        Discount.append(i.text.replace(\"% off\",\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "52f25f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP 100 sunglasses listings on flipkart.com:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>by Lenskart Polarized, UV Protection Rectangul...</td>\n",
       "      <td>749</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Singco India</td>\n",
       "      <td>Gradient, Toughened Glass Lens, UV Protection ...</td>\n",
       "      <td>598</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DAHAAZIL</td>\n",
       "      <td>UV Protection, Night Vision, Riding Glasses Wa...</td>\n",
       "      <td>177</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "      <td>639</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New Specs</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "      <td>264</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>UV Protection, Polarized Wayfarer Sunglasses (54)</td>\n",
       "      <td>759</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>PHENOMENAL</td>\n",
       "      <td>UV Protection Retro Square Sunglasses (Free Size)</td>\n",
       "      <td>369</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>kingsunglasses</td>\n",
       "      <td>UV Protection, Mirrored Round Sunglasses (Free...</td>\n",
       "      <td>265</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>kingsunglasses</td>\n",
       "      <td>Mirrored, UV Protection Wayfarer Sunglasses (53)</td>\n",
       "      <td>299</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (50)</td>\n",
       "      <td>569</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Brand                                Product Description Price  \\\n",
       "0    VINCENT CHASE  by Lenskart Polarized, UV Protection Rectangul...   749   \n",
       "1     Singco India  Gradient, Toughened Glass Lens, UV Protection ...   598   \n",
       "2         DAHAAZIL  UV Protection, Night Vision, Riding Glasses Wa...   177   \n",
       "3         Fastrack   UV Protection Rectangular Sunglasses (Free Size)   639   \n",
       "4        New Specs   UV Protection Rectangular Sunglasses (Free Size)   264   \n",
       "..             ...                                                ...   ...   \n",
       "95       ROYAL SON  UV Protection, Polarized Wayfarer Sunglasses (54)   759   \n",
       "96      PHENOMENAL  UV Protection Retro Square Sunglasses (Free Size)   369   \n",
       "97  kingsunglasses  UV Protection, Mirrored Round Sunglasses (Free...   265   \n",
       "98  kingsunglasses   Mirrored, UV Protection Wayfarer Sunglasses (53)   299   \n",
       "99       ROYAL SON          UV Protection Rectangular Sunglasses (50)   569   \n",
       "\n",
       "   Discount %  \n",
       "0          62  \n",
       "1          80  \n",
       "2          82  \n",
       "3          20  \n",
       "4          89  \n",
       "..        ...  \n",
       "95         62  \n",
       "96         81  \n",
       "97         84  \n",
       "98         85  \n",
       "99         71  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating dataframe for the first 100 sunglasses \n",
    "\n",
    "flipkart=pd.DataFrame({})\n",
    "flipkart['Brand']=brand[0:100]\n",
    "flipkart['Product Description']=Description[0:100]\n",
    "flipkart['Price']=Price[0:100]\n",
    "flipkart['Discount %']=Discount[0:100]\n",
    "\n",
    "print(\"TOP 100 sunglasses listings on flipkart.com:\\n\")\n",
    "flipkart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f925a15e",
   "metadata": {},
   "source": [
    "# Q6: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the search field. You have to scrape 4 attributes of each sneaker: 1. Brand 2. Product Description 3. Price "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "5c0bc3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(\"chromedriver.exe\")\n",
    "\n",
    "driver.get(\"https://www.flipkart.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "3cd6010d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter “sneakers” in “search for products, brands and more” field.\n",
    "search_product = driver.find_element(By.XPATH,\"//div[@class='_3OO5Xc']/input\")\n",
    "search_product.send_keys(\"sneakers\")\n",
    "# click the search button\n",
    "search_btn = driver.find_element(By.XPATH,\"//button[@class='L0Z3Pu']\")\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d2e16c",
   "metadata": {},
   "source": [
    "SCRAPING THE SPECIFIC URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "f42be621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specifying the url of the webpage to be scraped\n",
    "url = \"https://www.flipkart.com/search?q=sneakers&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off\"\n",
    "\n",
    "# open the webpage through our web driver\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "acb6c295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterating first 3 website pages to scrape the data\n",
    "\n",
    "page_url=[]\n",
    "\n",
    "url=driver.find_elements(By.XPATH,\"//nav[@class='yFHi8N']//a\")\n",
    "for i in url:\n",
    "    page_url.append(i.get_attribute('href'))\n",
    "page_url=page_url[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "255f21ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty list to scraping data into them\n",
    "\n",
    "brand=[]\n",
    "Description=[]\n",
    "Price=[]\n",
    "Discount=[] \n",
    "\n",
    "# extracting all the tags\n",
    "\n",
    "for i in page_url:\n",
    "    driver.get(i)\n",
    "    titles_brand=driver.find_elements(By.XPATH,\"//div[@class='_2WkVRV']\")\n",
    "    for i in titles_brand:\n",
    "        brand.append(i.text)\n",
    "        \n",
    "    titles_Description=driver.find_elements(By.XPATH,\"//a[@class='IRpwTa']\")\n",
    "    for i in titles_Description:\n",
    "        Description.append(i.text)\n",
    "        \n",
    "    titles_Price=driver.find_elements(By.XPATH,\"//div[@class='_30jeq3']\")\n",
    "    for i in titles_Price:\n",
    "        Price.append(i.text.replace(\"₹\",\"\"))\n",
    "        \n",
    "    titles_Discount=driver.find_elements(By.XPATH,\"//div[@class='_3Ay6Sb']/span\")\n",
    "    for i in titles_Discount:\n",
    "        Discount.append(i.text.replace(\"% off\",\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "3ca32eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 100 sneakers listings on flipkart.com:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Price₹</th>\n",
       "      <th>Discount %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LE GREEM</td>\n",
       "      <td>casual for men (blue 06) Sneakers For Men</td>\n",
       "      <td>499</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bluemaker</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>599</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WOODLAND</td>\n",
       "      <td>Modern Trendy Sneakers Shoes Sneakers For Men</td>\n",
       "      <td>2,096</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>Modern Trendy Sneakers Shoes Sneakers For Men</td>\n",
       "      <td>269</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>299</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>STRANGER BROTHERS</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>426</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>RapidBox</td>\n",
       "      <td>Trinity Sneakers For Men</td>\n",
       "      <td>650</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>BAUCHHAAR</td>\n",
       "      <td>Casual Shoes For Men Waliking,Sneaker,Loafers,...</td>\n",
       "      <td>449</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>luxury fashion</td>\n",
       "      <td>Modern Trendy Sneakers Shoes Sneakers For Men</td>\n",
       "      <td>426</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>BeFit</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>499</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Brand                                Product Description  \\\n",
       "0            LE GREEM          casual for men (blue 06) Sneakers For Men   \n",
       "1           bluemaker                                   Sneakers For Men   \n",
       "2            WOODLAND      Modern Trendy Sneakers Shoes Sneakers For Men   \n",
       "3              BRUTON      Modern Trendy Sneakers Shoes Sneakers For Men   \n",
       "4              BRUTON                                   Sneakers For Men   \n",
       "..                ...                                                ...   \n",
       "95  STRANGER BROTHERS                                   Sneakers For Men   \n",
       "96           RapidBox                           Trinity Sneakers For Men   \n",
       "97          BAUCHHAAR  Casual Shoes For Men Waliking,Sneaker,Loafers,...   \n",
       "98     luxury fashion      Modern Trendy Sneakers Shoes Sneakers For Men   \n",
       "99              BeFit                                   Sneakers For Men   \n",
       "\n",
       "   Price₹ Discount %  \n",
       "0     499         50  \n",
       "1     599         40  \n",
       "2   2,096         30  \n",
       "3     269         79  \n",
       "4     299         76  \n",
       "..    ...        ...  \n",
       "95    426         57  \n",
       "96    650         34  \n",
       "97    449         55  \n",
       "98    426         78  \n",
       "99    499         68  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating dataframe for the first 100 sneakers:\n",
    "\n",
    "flipkart=pd.DataFrame({})\n",
    "flipkart['Brand']=brand[0:100]\n",
    "flipkart['Product Description']=Description[0:100]\n",
    "flipkart['Price₹']=Price[0:100]\n",
    "flipkart['Discount %']=Discount[0:100]\n",
    "\n",
    "print(\"Top 100 sneakers listings on flipkart.com:\\n\")\n",
    "flipkart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b08458",
   "metadata": {},
   "source": [
    "# Q7: Go to the link - https://www.myntra.com/shoes https://www.myntra.com/shoes Set Price filter  , Color filter to “Black” And then scrape First 100 shoes data you get. The data should include “Brand” of the shoes , Short Shoe description, price of the shoe .\n",
    "Note: Applying the filter and scraping the data, everything should be done through code only and there should not be any manual step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "0af877a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(\"chromedriver.exe\")\n",
    "\n",
    "driver.get(\"https://www.myntra.com/shoes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "825e9d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the Price filter to “Rs. 7149 to Rs. 14099” by checking the respective boxe\n",
    "\n",
    "price = driver.find_elements(By.XPATH,\"//ul[@class ='price-list']//label[@class ='common-customCheckbox vertical-filters-label']/div[@class = 'common-checkboxIndicator']\") \n",
    "price[1].click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "b39cc8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the Color filter to “Black”  by checking the box\n",
    "\n",
    "color = driver.find_elements(By.XPATH,\"//li[@class ='colour-listItem']//label[@class ='common-customCheckbox']/div[@class = 'common-checkboxIndicator']\") \n",
    "color[0].click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "daf2fb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specifying the url of the webpage to be scraped\n",
    "url = \"https://www.myntra.com/shoes?f=Color%3ABlack_36454f&rf=Price%3A7149.0_14099.0_7149.0%20TO%2014099.0\"\n",
    "\n",
    "# open the webpage through our web driver\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "a76f8e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterating first 3 website pages to scrape the data\n",
    "\n",
    "page_url=[]\n",
    "\n",
    "url=driver.find_elements(By.XPATH,\"//li[@class='pagination-number']//a\")\n",
    "for i in url:\n",
    "    page_url.append(i.get_attribute('href'))\n",
    "page_url=page_url[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "34b6e281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty list to scraping data into them\n",
    "\n",
    "brand=[]\n",
    "Description=[]\n",
    "Price=[]\n",
    "\n",
    "# extracting all the tags\n",
    "\n",
    "for i in page_url:\n",
    "    driver.get(i)\n",
    "    titles_brand=driver.find_elements(By.XPATH,\"//h3[@class='product-brand']\")\n",
    "    for i in titles_brand:\n",
    "        brand.append(i.text)\n",
    "    \n",
    "    titles_Description=driver.find_elements(By.XPATH,\"//h4[@class='product-product']\")\n",
    "    for i in titles_Description:\n",
    "        Description.append(i.text)\n",
    "        \n",
    "    titles_Price=driver.find_elements(By.XPATH,\"//div[@class='product-price']\")\n",
    "    for i in titles_Price:\n",
    "        Price.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "72e4377c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 100 sneakers listings on myntra.com:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Shoe Description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ASICS</td>\n",
       "      <td>Men GEL-Quantum 360 6 Sports</td>\n",
       "      <td>Rs. 11199Rs. 13999(20% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Skechers</td>\n",
       "      <td>Men Textured Sneakers</td>\n",
       "      <td>Rs. 7999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Columbia</td>\n",
       "      <td>Men FACET OUTDRY Trekking Shoe</td>\n",
       "      <td>Rs. 12999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Geox</td>\n",
       "      <td>Men Perforations Sneakers</td>\n",
       "      <td>Rs. 12591Rs. 13990(10% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hush Puppies</td>\n",
       "      <td>Men Solid Leather Formal Slip-Ons</td>\n",
       "      <td>Rs. 8499Rs. 9999(15% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Louis Philippe</td>\n",
       "      <td>Men Solid Leather Formal Loafers</td>\n",
       "      <td>Rs. 9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Geox</td>\n",
       "      <td>Men Textured Leather Driving Shoes</td>\n",
       "      <td>Rs. 9891Rs. 10990(10% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Geox</td>\n",
       "      <td>Men Textured Leather Driving Shoes</td>\n",
       "      <td>Rs. 7693Rs. 10990(30% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Alberto Torresi</td>\n",
       "      <td>Men Solid Leather Mid-Top Formal Boots</td>\n",
       "      <td>Rs. 7999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Women Running Shoes</td>\n",
       "      <td>Rs. 11895Rs. 13995(15% OFF)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Brand                        Shoe Description  \\\n",
       "0             ASICS            Men GEL-Quantum 360 6 Sports   \n",
       "1          Skechers                   Men Textured Sneakers   \n",
       "2          Columbia          Men FACET OUTDRY Trekking Shoe   \n",
       "3              Geox               Men Perforations Sneakers   \n",
       "4      Hush Puppies       Men Solid Leather Formal Slip-Ons   \n",
       "..              ...                                     ...   \n",
       "95   Louis Philippe        Men Solid Leather Formal Loafers   \n",
       "96             Geox      Men Textured Leather Driving Shoes   \n",
       "97             Geox      Men Textured Leather Driving Shoes   \n",
       "98  Alberto Torresi  Men Solid Leather Mid-Top Formal Boots   \n",
       "99             Nike                     Women Running Shoes   \n",
       "\n",
       "                          Price  \n",
       "0   Rs. 11199Rs. 13999(20% OFF)  \n",
       "1                      Rs. 7999  \n",
       "2                     Rs. 12999  \n",
       "3   Rs. 12591Rs. 13990(10% OFF)  \n",
       "4     Rs. 8499Rs. 9999(15% OFF)  \n",
       "..                          ...  \n",
       "95                     Rs. 9999  \n",
       "96   Rs. 9891Rs. 10990(10% OFF)  \n",
       "97   Rs. 7693Rs. 10990(30% OFF)  \n",
       "98                     Rs. 7999  \n",
       "99  Rs. 11895Rs. 13995(15% OFF)  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating dataframe for the first 100 sneakers listings on myntra.com:\n",
    "\n",
    "myntra =pd.DataFrame({})\n",
    "myntra['Brand']=brand[0:100]\n",
    "myntra['Shoe Description']=Description[0:100]\n",
    "myntra['Price']=Price[0:100]\n",
    "\n",
    "print(\"Top 100 sneakers listings on myntra.com:\\n\")\n",
    "myntra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "ca93e7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#close the driver\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c1b475",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "922fbeea",
   "metadata": {},
   "source": [
    "# Q8: Go to webpage https://www.amazon.in/\n",
    "Enter “Laptop” in the search field and then click the search icon.\n",
    "Then set CPU Type filter to “Intel Core i7” After setting the filters scrape first 10 laptops data. You have to scrape 3 attributes for each laptop:\n",
    "1. Title\n",
    "2. Ratings\n",
    "3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "9b54e8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(\"chromedriver.exe\")\n",
    "\n",
    "driver.get(\"https://www.amazon.in/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "740103ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter “laptop” in the search field.\n",
    "search_product = driver.find_element(By.XPATH,\"//div[@class='nav-search-field ']/input\")\n",
    "search_product.send_keys(\"laptop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "ac1171f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# click the search button\n",
    "search_btn = driver.find_element(By.XPATH,\"//div[@class='nav-search-submit nav-sprite']\")\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "f7afb6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying CPU Type filter to “Intel Core i7” filter by checking the respective box\n",
    "i7_clk=driver.find_elements(By.XPATH,\"//span[@class='a-size-base a-color-base']\")\n",
    "for i in i7_clk:\n",
    "    if i.text == 'Intel Core i7':   \n",
    "        i.click() # Checking the checkbox to apply filter on the laptop\n",
    "        break  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "82d9b33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty list to scraping data into them\n",
    "\n",
    "Title=[]\n",
    "Rating=[]\n",
    "Price=[]\n",
    "\n",
    "# extracting all the tags\n",
    "\n",
    "titles=driver.find_elements(By.XPATH,\"//h2[@class='a-size-mini a-spacing-none a-color-base s-line-clamp-2']\")\n",
    "for i in titles:\n",
    "    Title.append(i.text)\n",
    "    \n",
    "titles_rat=driver.find_elements(By.XPATH,\"//div[@class='a-row a-size-small']/span\")\n",
    "for i in titles_rat:\n",
    "    Rating.append(i.get_attribute(\"aria-label\"))\n",
    "        \n",
    "titles_Price=driver.find_elements(By.XPATH,\"//span[@class='a-price']\")\n",
    "for i in titles_Price:\n",
    "    Price.append(i.text[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "7edca0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extratcing ratings from the unorganised rating tag\n",
    "\n",
    "rating=[]\n",
    "for i in range(0,len(Rating)):\n",
    "    if i == 0 or  i/2 == i//2:\n",
    "        rating.append(Rating[i][0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "b7f473b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data for the first 10 laptops data on amazon.com:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hp Pavilion 15 12Th Gen Intel Core I7 16Gb Sdr...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>87,900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hp Pavilion X360 11Th Gen Intel Core I7 14 Inc...</td>\n",
       "      <td>4.2</td>\n",
       "      <td>82,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HP Pavilion 14 12th Gen Intel Core i7 16GB SDR...</td>\n",
       "      <td>3.7</td>\n",
       "      <td>86,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ASUS TUF Gaming F15 (2022), 15.6-inch (39.62 c...</td>\n",
       "      <td>4.3</td>\n",
       "      <td>1,12,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HP Envy 11th Gen Intel Evo Core i7 14 inch(35....</td>\n",
       "      <td>3.7</td>\n",
       "      <td>99,499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Samsung Galaxy Book2 Intel 12th Gen core i7 39...</td>\n",
       "      <td>3.2</td>\n",
       "      <td>79,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LG Gram 16 Intel Evo 11th Gen i7 Thin &amp; Light ...</td>\n",
       "      <td>4.3</td>\n",
       "      <td>85,499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Lenovo ThinkBook 13s Intel 11th Gen Core i7 13...</td>\n",
       "      <td>3.8</td>\n",
       "      <td>89,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ASUS TUF Gaming F15 (2021) 15.6-inch (39.62 cm...</td>\n",
       "      <td>4.4</td>\n",
       "      <td>88,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Lenovo ThinkBook 15 Intel 11th Gen Core i7 15....</td>\n",
       "      <td>4.3</td>\n",
       "      <td>86,990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title Rating     Price\n",
       "0  Hp Pavilion 15 12Th Gen Intel Core I7 16Gb Sdr...    4.0    87,900\n",
       "1  Hp Pavilion X360 11Th Gen Intel Core I7 14 Inc...    4.2    82,990\n",
       "2  HP Pavilion 14 12th Gen Intel Core i7 16GB SDR...    3.7    86,990\n",
       "3  ASUS TUF Gaming F15 (2022), 15.6-inch (39.62 c...    4.3  1,12,990\n",
       "4  HP Envy 11th Gen Intel Evo Core i7 14 inch(35....    3.7    99,499\n",
       "5  Samsung Galaxy Book2 Intel 12th Gen core i7 39...    3.2    79,990\n",
       "6  LG Gram 16 Intel Evo 11th Gen i7 Thin & Light ...    4.3    85,499\n",
       "7  Lenovo ThinkBook 13s Intel 11th Gen Core i7 13...    3.8    89,990\n",
       "8  ASUS TUF Gaming F15 (2021) 15.6-inch (39.62 cm...    4.4    88,990\n",
       "9  Lenovo ThinkBook 15 Intel 11th Gen Core i7 15....    4.3    86,990"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating dataframe for the first 10 laptops data on amazon.com:\n",
    "\n",
    "amazon =pd.DataFrame({})\n",
    "amazon['Title']=Title[0:10]\n",
    "amazon['Rating']=rating[0:10]\n",
    "amazon['Price']=Price[0:10]\n",
    "\n",
    "print(\"The data for the first 10 laptops data on amazon.com:\\n\")\n",
    "amazon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe91cac",
   "metadata": {},
   "source": [
    "# Q9: Write a python program to scrape data for first 10 job results for Data Scientist Designation in Noida location. You have to scrape company name, No. of days ago when job was posted, Rating of the company.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.ambitionbox.com/\n",
    "2. Click on the Job option\n",
    "3. After reaching to the next webpage, In place of “Search by Designations, Companies, Skills” enter “Data Scientist” and click on search button.\n",
    "4. You will reach to the following web page click on location and in place of “Search location” enter “Noida” and select location “Noida”.\n",
    "5. Then scrape the data for the first 10 jobs results you get on the above shown page.\n",
    "6. Finally create a dataframe of the scraped data.\n",
    "Note: All the steps required during scraping should be done through code only and not manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "b8bbd6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(\"chromedriver.exe\")\n",
    "\n",
    "driver.get(\" https://www.ambitionbox.com//\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "2b7dc594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# click the \"Jobs\" webpage\n",
    "cl_job = driver.find_element(By.XPATH,\"//a[@class='link jobs']\")\n",
    "cl_job.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "13ea11ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In place of “Search by Designations, Companies, Skills” enter “Data Scientist” \n",
    "\n",
    "search_title = driver.find_element(By.XPATH,\"//span[@class='twitter-typeahead']/input\")\n",
    "search_title.send_keys(\"Data Scientist\")\n",
    "\n",
    "#click on search button.\n",
    "search_btn = driver.find_element(By.XPATH,\"//button[@class='ab_btn search-btn round']\")\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "c321321e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_loc = driver.find_element(By.XPATH,\"//div[@class='show-flex']/div[2]\") # Location dropdown\n",
    "cl_loc.click()    \n",
    "driver.find_element(By.XPATH,'/html/body/div/div/div/div[2]/div[1]/div[2]/div[1]/div/div/div/div[2]/div[2]/div/div[2]/input').send_keys('Noida')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "42478336",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.XPATH,'/html/body/div/div/div/div[2]/div[1]/div[2]/div[1]/div/div/div/div[2]/div[2]/div/div[3]/div[1]/div[1]/div/label').click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "4925a201",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping company name, No. of days ago when job was posted, Rating of the company\n",
    "\n",
    "#creating empty list\n",
    "company_name = []\n",
    "job_posted = []\n",
    "rating = []\n",
    "\n",
    "#Scraing all tags\n",
    "\n",
    "company=driver.find_elements(By.XPATH,\"//div[@class='company-info']\")\n",
    "for i in company:\n",
    "    company_name.append(i.text.split(\"\\n\")[0])\n",
    "    rating.append(i.text.split(\"\\n\")[1])\n",
    "    \n",
    "posted=driver.find_elements(By.XPATH,\"//span[@class='body-small-l']\")\n",
    "for i in posted:\n",
    "    job_posted.append(i.text)\n",
    "    \n",
    "# extratcing job posted days from the unorganised job posted tag\n",
    "\n",
    "posted=[]\n",
    "for i in range(0,len(job_posted)):\n",
    "    if i == 0 or  i/2 == i//2:\n",
    "        posted.append(job_posted[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "12bac2a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data for the first 10 jobs results in ambitionbox.com :\n",
      " \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_name</th>\n",
       "      <th>Job_Posted</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Optum Global Solutions (India) Private Limited</td>\n",
       "      <td>7d ago</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GENPACT India Private Limited</td>\n",
       "      <td>14d ago</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GENPACT India Private Limited</td>\n",
       "      <td>1mon ago</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>InfoEdge India Ltd.</td>\n",
       "      <td>12d ago</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dew Solutions Pvt. Ltd.</td>\n",
       "      <td>5d ago</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Info Edge India Limited</td>\n",
       "      <td>13d ago</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Info Edge India Limited</td>\n",
       "      <td>13d ago</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Latent bridge</td>\n",
       "      <td>13d ago</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Careerera</td>\n",
       "      <td>12hr ago</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Careernet Consulting</td>\n",
       "      <td>27d ago</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Company_name Job_Posted Rating\n",
       "0  Optum Global Solutions (India) Private Limited     7d ago    4.1\n",
       "1                   GENPACT India Private Limited    14d ago    4.0\n",
       "2                   GENPACT India Private Limited   1mon ago    4.0\n",
       "3                             InfoEdge India Ltd.    12d ago    3.9\n",
       "4                         Dew Solutions Pvt. Ltd.     5d ago    4.3\n",
       "5                         Info Edge India Limited    13d ago    3.9\n",
       "6                         Info Edge India Limited    13d ago    3.9\n",
       "7                                   Latent bridge    13d ago    4.5\n",
       "8                                       Careerera   12hr ago    3.8\n",
       "9                            Careernet Consulting    27d ago    3.9"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating Dataframe \n",
    "\n",
    "ambition = pd.DataFrame({})\n",
    "ambition[\"Company_name\"] = company_name[1:]\n",
    "ambition[\"Job_Posted\"] = posted\n",
    "ambition[\"Rating\"] = rating[1:]\n",
    "\n",
    "print(\"The data for the first 10 jobs results in ambitionbox.com :\\n \")\n",
    "ambition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ad6fec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d241b7ee",
   "metadata": {},
   "source": [
    "# Q10: Write a python program to scrape the salary data for Data Scientist designation. You have to scrape Company name, Number of salaries, Average salary, Min salary, Max Salary.\n",
    "The above task will be, done as shown in the below steps:\n",
    "1. First get the webpage https://www.ambitionbox.com/\n",
    "2. Click on the salaries option\n",
    "3. After reaching to the following webpage, In place of “Search Job Profile” enters “Data Scientist” and then click on “Data Scientist”.\n",
    "4. Scrape the data for the first 10 companies. Scrape the company name, total salary record, average salary, minimum salary, maximum salary, experience required.\n",
    "5. Store the data in a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "61d2bd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(\"chromedriver.exe\")\n",
    "\n",
    "driver.get(\" https://www.ambitionbox.com//\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "14ae92f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# click on Salary webpage\n",
    "driver.find_element(By.XPATH,\"//a[@class='link salaries']\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "49acefe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In place of “Search Job Profile” enters “Data Scientist” and then click on “Data Scientist”.\n",
    "search_job = driver.find_element(By.ID,\"jobProfileSearchbox\")\n",
    "search_job.send_keys(\"Data Scientist\")\n",
    "\n",
    "clk=driver.find_elements(By.XPATH,\"//div[@class='suggestion_wrap tt-suggestion tt-selectable']\")\n",
    "for i in clk:\n",
    "    if i.text == 'Data Scientist':   \n",
    "        i.click() # click on “Data Scientist”\n",
    "        break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "0c4afdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrape Company name, Number of salaries, Average salary, Min salary, Max Salary, experience required.\n",
    "\n",
    "company_name = []\n",
    "salary_record = []\n",
    "average_salary = []\n",
    "min_salary = []\n",
    "max_salary = []\n",
    "exp = []\n",
    "\n",
    "#Scraing all tags\n",
    "\n",
    "company=driver.find_elements(By.XPATH,\"//div[@class='company-info']\")\n",
    "for i in company:\n",
    "    company_name.append(i.text.split(\"\\n\")[0])                              #company name\n",
    "    salary_record.append(i.text.replace(\"based on\", \" \").replace(\"salaries\",\"\").split(\"\\n\")[1:2]) #Total Salary Record\n",
    "    exp.append(i.text.replace(\"yrs exp\",\"\").replace(\"yr exp\",\"\").split(\"\\n\")[-1])                # Experience required\n",
    "    \n",
    "avg_salary=driver.find_elements(By.XPATH,\"//div[@class='average-indicator-wrapper']\")\n",
    "for i in avg_salary:\n",
    "    average_salary.append(i.text.replace(\"₹\",\"\").replace(\"L\",\"\"))            # average salary\n",
    "\n",
    "salary=driver.find_elements(By.XPATH,\"//div[@class='salary-values']\")\n",
    "for i in salary:\n",
    "    min_salary.append(i.text.replace(\"₹\",\"\").replace(\"L\",\"\").split(\"\\n\")[0])  # minimum salary\n",
    "    max_salary.append(i.text.replace(\"₹\",\"\").replace(\"L\",\"\").split(\"\\n\")[1])  # maximum salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "ae3efe71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " first 10 Companies results in ambitionbox.com :\n",
      " \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Total_Salary_Record</th>\n",
       "      <th>Experience_Required</th>\n",
       "      <th>Average_Salary_L</th>\n",
       "      <th>Minimum_Salary_L</th>\n",
       "      <th>Maximum_Salary_L</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Walmart</td>\n",
       "      <td>[Data Scientist Salary]</td>\n",
       "      <td>3 erience (based on 12 salaries)</td>\n",
       "      <td>30.6</td>\n",
       "      <td>25.0</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ab Inbev</td>\n",
       "      <td>[Data Scientist Salary]</td>\n",
       "      <td>3-4 erience (based on 33 salaries)</td>\n",
       "      <td>20.8</td>\n",
       "      <td>15.0</td>\n",
       "      <td>26.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ZS</td>\n",
       "      <td>[Data Scientist Salary]</td>\n",
       "      <td>2 erience (based on 15 salaries)</td>\n",
       "      <td>16.7</td>\n",
       "      <td>11.0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Optum</td>\n",
       "      <td>[Data Scientist Salary]</td>\n",
       "      <td>3-4 erience (based on 32 salaries)</td>\n",
       "      <td>15.9</td>\n",
       "      <td>11.0</td>\n",
       "      <td>22.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Reliance Jio</td>\n",
       "      <td>[Data Scientist Salary]</td>\n",
       "      <td>3-4 erience (based on 21 salaries)</td>\n",
       "      <td>15.7</td>\n",
       "      <td>5.6</td>\n",
       "      <td>26.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Fractal Analytics</td>\n",
       "      <td>[Data Scientist Salary]</td>\n",
       "      <td>2-4 erience (based on 89 salaries)</td>\n",
       "      <td>15.5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Tiger Analytics</td>\n",
       "      <td>[Data Scientist Salary]</td>\n",
       "      <td>2-4 erience (based on 51 salaries)</td>\n",
       "      <td>14.8</td>\n",
       "      <td>9.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>UnitedHealth</td>\n",
       "      <td>[Data Scientist Salary]</td>\n",
       "      <td>2-4 erience (based on 57 salaries)</td>\n",
       "      <td>14.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>21.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>EXL Service</td>\n",
       "      <td>[Data Scientist Salary]</td>\n",
       "      <td>3-4 erience (based on 21 salaries)</td>\n",
       "      <td>13.2</td>\n",
       "      <td>7.6</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Deloitte</td>\n",
       "      <td>[Data Scientist Salary]</td>\n",
       "      <td>2-4 erience (based on 69 salaries)</td>\n",
       "      <td>12.8</td>\n",
       "      <td>7.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Company_Name      Total_Salary_Record  \\\n",
       "0            Walmart  [Data Scientist Salary]   \n",
       "1           Ab Inbev  [Data Scientist Salary]   \n",
       "2                 ZS  [Data Scientist Salary]   \n",
       "3              Optum  [Data Scientist Salary]   \n",
       "4       Reliance Jio  [Data Scientist Salary]   \n",
       "5  Fractal Analytics  [Data Scientist Salary]   \n",
       "6    Tiger Analytics  [Data Scientist Salary]   \n",
       "7       UnitedHealth  [Data Scientist Salary]   \n",
       "8        EXL Service  [Data Scientist Salary]   \n",
       "9           Deloitte  [Data Scientist Salary]   \n",
       "\n",
       "                  Experience_Required Average_Salary_L Minimum_Salary_L  \\\n",
       "0    3 erience (based on 12 salaries)             30.6             25.0   \n",
       "1  3-4 erience (based on 33 salaries)             20.8             15.0   \n",
       "2    2 erience (based on 15 salaries)             16.7             11.0   \n",
       "3  3-4 erience (based on 32 salaries)             15.9             11.0   \n",
       "4  3-4 erience (based on 21 salaries)             15.7              5.6   \n",
       "5  2-4 erience (based on 89 salaries)             15.5             10.0   \n",
       "6  2-4 erience (based on 51 salaries)             14.8              9.0   \n",
       "7  2-4 erience (based on 57 salaries)             14.0              8.3   \n",
       "8  3-4 erience (based on 21 salaries)             13.2              7.6   \n",
       "9  2-4 erience (based on 69 salaries)             12.8              7.0   \n",
       "\n",
       "  Maximum_Salary_L  \n",
       "0             36.0  \n",
       "1             26.2  \n",
       "2             22.0  \n",
       "3             22.5  \n",
       "4             26.2  \n",
       "5             23.0  \n",
       "6             20.0  \n",
       "7             21.1  \n",
       "8             21.0  \n",
       "9             25.0  "
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating Dataframe for the company name, total salary record, average salary, minimum salary, maximum salary, experience required.\n",
    "\n",
    "ambition =pd.DataFrame({})\n",
    "ambition[\"Company_Name\"] = company_name[:10]\n",
    "ambition[\"Total_Salary_Record\"] = salary_record[:10]\n",
    "ambition[\"Experience_Required\"] = exp[:10]\n",
    "ambition[\"Average_Salary_L\"] = average_salary[:10]\n",
    "ambition[\"Minimum_Salary_L\"] = min_salary\n",
    "ambition[\"Maximum_Salary_L\"] = max_salary\n",
    "\n",
    "print(\" first 10 Companies results in ambitionbox.com :\\n \")\n",
    "ambition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfe1c2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
